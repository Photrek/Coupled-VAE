{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coupledvae_v4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEJjn06qaEDP"
      },
      "source": [
        "#### **1) Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPyJih55aEDQ"
      },
      "source": [
        "# Don't forget to restart\n",
        "# !pip install -U tensorflow_probability -q\n",
        "#!pip install ipdb tensorflow==2.5.0 -q\n",
        "!pip install ipdb -q\n",
        "# !pip install git+https://github.com/tensorflow/docs -q\n",
        "# !pip install -U -i https://test.pypi.org/simple/ nsc -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_sk90OFaEDT"
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "import ipdb\n",
        "import math\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "from tensorflow.keras.layers import Input, InputLayer, Lambda, Reshape, Dropout, \\\n",
        "                                    Flatten, Dense, Conv2D, Conv2DTranspose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH0o4f7xUfUQ"
      },
      "source": [
        "pip list | grep tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1M4C3hA88oN"
      },
      "source": [
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "    print('WARNING: GPU device not found.')\n",
        "else:\n",
        "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTEQ7kMIQ8cg"
      },
      "source": [
        "# List all physical devices\n",
        "tf.config.list_physical_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1m4X6DJGb52"
      },
      "source": [
        "If using Google Colab, save in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpWSzBBGayV"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RKA0uShaEDW"
      },
      "source": [
        "#### **2) Extract Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63HS2FEDhIVY"
      },
      "source": [
        "BATCH_SIZE_TRAIN = 256  # 128\n",
        "BATCH_SIZE_TEST = 5000  # 10000\n",
        "random_seed = datetime.now().microsecond  # random seed is the microsecond for current time\n",
        "#random_seed = 1234567\n",
        "\n",
        "# corrupted_names = ['identity', 'motion_blur', 'translate', 'rotate', 'brightness', 'fog', 'shot_noise']\n",
        "corrupted_names = ['identity', 'motion_blur', 'translate', 'rotate']\n",
        "datasets_names = ['mnist'] + [f'mnist_corrupted/{corrupted_name}' for corrupted_name in corrupted_names]\n",
        "# datasets_names = ['mnist', 'mnist_corrupted', 'fashion_mnist', 'cifar10', 'cifar10_corrupted/motion_blur']\n",
        "datasets_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLK9JGGnJpaG"
      },
      "source": [
        "def _preprocess(sample):\n",
        "    image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "    return image\n",
        "\n",
        "def _preprocess_label(sample):\n",
        "    label = tf.cast(sample['label'], tf.int32)\n",
        "    return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLJo9s78GhLo"
      },
      "source": [
        "def get_datasets(datasets_names, batch_size_train, batch_size_test):\n",
        "    datasets = defaultdict(dict)\n",
        "    for datasets_name in datasets_names:\n",
        "        print(f\"============================================================================================\")\n",
        "        print(f\"\\nExtracting {datasets_name.upper()} dataset...\\n\")\n",
        "        datasets_raw, datasets_raw_info = tfds.load(name=datasets_name,\n",
        "                                                    with_info=True,\n",
        "                                                    as_supervised=False\n",
        "                                                    )\n",
        "        print(datasets_raw_info)\n",
        "\n",
        "        # View some examples from the dataset\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
        "        fig.subplots_adjust(hspace=0.2, wspace=0.1)\n",
        "        for i, (elem, ax) in enumerate(zip(datasets_raw['train'], axes.flat)):\n",
        "            image = tf.squeeze(elem['image'])\n",
        "            # print(image)\n",
        "            label = elem['label']\n",
        "\n",
        "            ax.imshow(image, cmap='gray')\n",
        "            ax.text(0.7, -0.12, f'Digit = {label}', ha='right',\n",
        "                    transform=ax.transAxes, color='black')\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # plt.show()\n",
        "\n",
        "        # Get\n",
        "        batch_size = batch_size_train if datasets_name == 'mnist' else batch_size_test\n",
        "        train_size = 60000 if 'mnist' in datasets_name else 50000\n",
        "        if 'corrupted' not in datasets_name:\n",
        "            datasets[datasets_name]['train'] = (datasets_raw['train']\n",
        "                                                .map(_preprocess)\n",
        "                                                .batch(batch_size)\n",
        "                                                .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "                                                .shuffle(train_size, seed=random_seed)\n",
        "                                                )\n",
        "        datasets[datasets_name]['test'] = (datasets_raw['test']\n",
        "                                           .map(_preprocess)\n",
        "                                           .batch(batch_size)\n",
        "                                           .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "                                           )\n",
        "        datasets[datasets_name]['test_label'] = (datasets_raw['test']\n",
        "                                                 .map(_preprocess_label)\n",
        "                                                 .batch(batch_size)\n",
        "                                                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "                                                 )\n",
        "\n",
        "        if 'corrupted' not in datasets_name:\n",
        "            #\n",
        "            print(\" - Print one train set image:\")\n",
        "            for train_batch in datasets[datasets_name]['train'].take(1):\n",
        "                image = train_batch[0].numpy()\n",
        "            image = np.squeeze(image)\n",
        "            plt.figure()\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.colorbar()\n",
        "            plt.grid(False)\n",
        "            plt.axis('off')\n",
        "            plt.show();\n",
        "\n",
        "        #\n",
        "        print(\" - Print one test set image:\")\n",
        "        for test_batch in datasets[datasets_name]['test'].take(1):\n",
        "            image = test_batch[0].numpy()\n",
        "        image = np.squeeze(image)\n",
        "        plt.figure()\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.colorbar()\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.show();\n",
        "\n",
        "        #\n",
        "        print(\" - Print one test set label:\")\n",
        "        for test_label in datasets[datasets_name]['test_label'].take(1):\n",
        "            label = test_label[0]\n",
        "        print(label.numpy())\n",
        "        print(f\"\\n\")\n",
        "\n",
        "    return datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aje9Fba3KAFC"
      },
      "source": [
        "%%time\n",
        "datasets = get_datasets(datasets_names, BATCH_SIZE_TRAIN, BATCH_SIZE_TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l8yXrzwe2SR"
      },
      "source": [
        "tf.Tensor(0.12891072, shape=(), dtype=float32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVzaNn7KtRmM"
      },
      "source": [
        "'''\n",
        "0\tT-shirt/top\n",
        "1\tTrouser\n",
        "2\tPullover\n",
        "3\tDress\n",
        "4\tCoat\n",
        "5\tSandal\n",
        "6\tShirt\n",
        "7\tSneaker\n",
        "8\tBag\n",
        "9\tAnkle boot\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-B5QF0uG_GM"
      },
      "source": [
        "CIFAR-10 item mapping:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGOMakeqG-sE"
      },
      "source": [
        "'''\n",
        "0\tairplane\n",
        "1\tautomobile\n",
        "2\tbird\n",
        "3\tcat\n",
        "4\tdeer\n",
        "5\tdog\n",
        "6\tfrog\n",
        "7\thorse\n",
        "8\tship\n",
        "9\ttruck boot\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zopEYyzVZynY"
      },
      "source": [
        "#### **3) Model Class**\n",
        "\n",
        "Credit: https://www.tensorflow.org/api_docs/python/tf/keras/datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBmkn8hgDWt4"
      },
      "source": [
        "!pip install -i https://test.pypi.org/simple/ nsc-tf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QJN4AtF5kpP"
      },
      "source": [
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "import nsc_tf\n",
        "from math import pi\n",
        "\n",
        "from tensorflow import repeat, squeeze, reduce_mean, matmul, expand_dims, \\\n",
        "                       transpose, reduce_prod, pow, square, sqrt, cast, \\\n",
        "                       where, zeros_like, int32, float32, equal, reduce_all \n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.math import log, lgamma, exp, is_finite, reduce_sum, \\\n",
        "                            count_nonzero, add, subtract, multiply, divide\n",
        "from tensorflow.linalg import det, diag_part, inv, trace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5i8DixeY8kG"
      },
      "source": [
        "class Sampler_Z(tfkl.Layer):   \n",
        "\n",
        "  def call(self, inputs):\n",
        "    mean, logvar = inputs\n",
        "    # Reparameterize\n",
        "    eps = tf.random.normal(shape=mean.shape, seed=0)\n",
        "    z_sample = eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    #tf.print(tf.math.reduce_mean(eps))\n",
        "\n",
        "    return z_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UudCMLdsxNV"
      },
      "source": [
        "# Encoder/Decoder layers 1 (for MNIST images)\n",
        "class EncoderZ_1(tfkl.Layer):\n",
        "\n",
        "    def __init__(self, z_dim, n_filter_base, seed, name=\"encoder\", **kwargs):\n",
        "        super(EncoderZ_1, self).__init__(name=name, **kwargs)\n",
        "        # Block-1\n",
        "        self.conv_layer_1 = tfkl.Conv2D(filters=n_filter_base, kernel_size=3,\n",
        "                                        strides=1, padding='same', name='conv_1'\n",
        "                                        )\n",
        "\n",
        "        self.batch_layer_1 = tfkl.BatchNormalization(name='bn_1')\n",
        "        self.activation_layer_1 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_1')\n",
        "        # Block-2\n",
        "        self.conv_layer_2 = tfkl.Conv2D(filters=n_filter_base*2, kernel_size=3,\n",
        "                                        strides=2, padding='same', name='conv_2'\n",
        "                                        )\n",
        "        self.batch_layer_2 = tfkl.BatchNormalization(name='bn_2')\n",
        "        self.activation_layer_2 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_2')\n",
        "        # Block-3\n",
        "        self.conv_layer_3 = tfkl.Conv2D(filters=n_filter_base*2, kernel_size=3,\n",
        "                                        strides=2, padding='same', name='conv_3'\n",
        "                                        )\n",
        "        self.batch_layer_3 = tfkl.BatchNormalization(name='bn_3')\n",
        "        self.activation_layer_3 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_3')\n",
        "        # Block-4\n",
        "        self.conv_layer_4 = tfkl.Conv2D(filters=n_filter_base*2, kernel_size=3,\n",
        "                                        strides=1, padding='same', name='conv_4'\n",
        "                                        )\n",
        "        self.batch_layer_4 = tfkl.BatchNormalization(name='bn_4')\n",
        "        self.activation_layer_4 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_4')\n",
        "        # Final Block\n",
        "        self.flatten_layer = Flatten()\n",
        "        self.dense_mean = Dense(z_dim, activation=None, name='z_mean')\n",
        "        self.dense_raw_stddev = Dense(z_dim, activation=None,\n",
        "                                      name='z_raw_stddev'\n",
        "                                      )\n",
        "        self.sampler_z = Sampler_Z()\n",
        "\n",
        "    # Functional\n",
        "    def call(self, x_input):\n",
        "        z = self.conv_layer_1(x_input)\n",
        "        z = self.batch_layer_1(z)\n",
        "        z = self.activation_layer_1(z)\n",
        "        z = self.conv_layer_2(z)\n",
        "        z = self.batch_layer_2(z)\n",
        "        z = self.activation_layer_2(z)\n",
        "        z = self.conv_layer_3(z)\n",
        "        z = self.batch_layer_3(z)\n",
        "        z = self.activation_layer_3(z)\n",
        "        z = self.conv_layer_4(z)\n",
        "        z = self.batch_layer_4(z)\n",
        "        z = self.activation_layer_4(z)\n",
        "        z = self.flatten_layer(z)\n",
        "        mean = self.dense_mean(z)\n",
        "        logvar = self.dense_raw_stddev(z)\n",
        "        z_sample = self.sampler_z((mean, logvar))\n",
        "        return z_sample, mean, logvar\n",
        "\n",
        "\n",
        "class DecoderX_1(tfkl.Layer):\n",
        "\n",
        "    def __init__(self, z_dim, n_filter_base, name=\"decoder\", **kwargs):\n",
        "        super(DecoderX_1, self).__init__(name=name, **kwargs)\n",
        "        # For MNIST images\n",
        "        self.dense_z_input = tfkl.Dense(units=7*7*n_filter_base*2,\n",
        "                                        activation=tf.nn.relu\n",
        "                                        )\n",
        "        self.reshape_layer = tfkl.Reshape(target_shape=(7, 7, n_filter_base*2))\n",
        "        # Block-1\n",
        "        self.conv_transpose_layer_1 = tfkl.Conv2DTranspose(filters=n_filter_base*2,\n",
        "                                                           kernel_size=3,\n",
        "                                                           strides=1, \n",
        "                                                           padding='same',\n",
        "                                                           name='conv_transpose_1'\n",
        "                                                           )\n",
        "        self.batch_layer_1 = tfkl.BatchNormalization(name='bn_1')\n",
        "        self.activation_layer_1 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_1')\n",
        "        # Block-2\n",
        "        self.conv_transpose_layer_2 = tfkl.Conv2DTranspose(filters=n_filter_base*2,\n",
        "                                                           kernel_size=3,\n",
        "                                                           strides=2, \n",
        "                                                           padding='same',\n",
        "                                                           name='conv_transpose_2'\n",
        "                                                           )\n",
        "        self.batch_layer_2 = tfkl.BatchNormalization(name='bn_2')\n",
        "        self.activation_layer_2 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_2')\n",
        "        # Block-3\n",
        "        self.conv_transpose_layer_3 = tfkl.Conv2DTranspose(filters=n_filter_base,\n",
        "                                                           kernel_size=3,\n",
        "                                                           strides=2, \n",
        "                                                           padding='same',\n",
        "                                                           name='conv_transpose_3'\n",
        "                                                           )\n",
        "        self.batch_layer_3 = tfkl.BatchNormalization(name='bn_3')\n",
        "        self.activation_layer_3 = tfkl.Activation(tf.nn.leaky_relu, name='lrelu_3')\n",
        "        # Block-4\n",
        "        # Filters=1 for gray-scaled images\n",
        "        self.conv_transpose_layer_4 = tfkl.Conv2DTranspose(filters=1,\n",
        "                                                           kernel_size=3,\n",
        "                                                           strides=1, \n",
        "                                                           padding='same',\n",
        "                                                           name='conv_transpose_4'\n",
        "                                                           )\n",
        "\n",
        "    # Functional\n",
        "    def call(self, z):\n",
        "        x_output = self.dense_z_input(z)\n",
        "        x_output = self.reshape_layer(x_output)\n",
        "        x_output = self.conv_transpose_layer_1(x_output)\n",
        "        x_output = self.batch_layer_1(x_output)\n",
        "        x_output = self.activation_layer_1(x_output)\n",
        "        x_output = self.conv_transpose_layer_2(x_output)\n",
        "        x_output = self.batch_layer_2(x_output)\n",
        "        x_output = self.activation_layer_2(x_output)\n",
        "        x_output = self.conv_transpose_layer_3(x_output)\n",
        "        x_output = self.batch_layer_3(x_output)\n",
        "        x_output = self.activation_layer_3(x_output)\n",
        "        x_output = self.conv_transpose_layer_4(x_output)\n",
        "        return x_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q5aKhDpKkhl"
      },
      "source": [
        "class VAEModel(tfk.Model):\n",
        "    \"\"\"Convolutional variational autoencoder base model.\"\"\"\n",
        "\n",
        "    def __init__(self, z_dim, n_filter_base, seed):\n",
        "        super(VAEModel, self).__init__()\n",
        "        self.encoder = EncoderZ_1(z_dim, n_filter_base, seed)\n",
        "        self.decoder = DecoderX_1(z_dim, n_filter_base)\n",
        "\n",
        "    #@tf.function\n",
        "    def sample(self, z_sample):\n",
        "        x_recons_logits = self.decoder(z_sample)\n",
        "        sample_images = tf.sigmoid(x_recons_logits)  # predictions\n",
        "        return sample_images\n",
        "\n",
        "    def call(self, x_input):\n",
        "        z_sample, mean, logvar = self.encoder(x_input)\n",
        "        x_recons_logits = self.decoder(z_sample)\n",
        "        return x_recons_logits, z_sample, mean, logvar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPYki3SJIPOQ"
      },
      "source": [
        "class GeneralizedMean:\n",
        "\n",
        "    def __init__(self, ll_values, kl_values):\n",
        "        self.gmean_metrics = pd.Series()\n",
        "        self.gmean_log_prob_values = {}\n",
        "        self._save_generalized_mean_metrics('elbo', ll_values - kl_values)\n",
        "        self._save_generalized_mean_metrics('recon', ll_values)\n",
        "        self._save_generalized_mean_metrics('kldiv', -kl_values)\n",
        "\n",
        "    def _save_generalized_mean_metrics(self, key, log_prob_values):\n",
        "        # Save the generalized means and metric values\n",
        "        prob_values = tf.exp(log_prob_values)\n",
        "        self.inv_n = 1 / len(prob_values)  # 1/n\n",
        "        decisiveness = self._calculate_decisiveness(prob_values)\n",
        "        accuracy = self._calculate_accuracy(prob_values)\n",
        "        robustness = self._calculate_robustness(prob_values)\n",
        "        curr_metrics = pd.Series([decisiveness, accuracy, robustness],\n",
        "                                 index=[f'{key}_decisiveness', f'{key}_accuracy',\n",
        "                                        f'{key}_robustness'\n",
        "                                        ]\n",
        "                                 )\n",
        "        self.gmean_metrics = self.gmean_metrics.append(curr_metrics)\n",
        "        self.gmean_log_prob_values[key] = log_prob_values\n",
        "\n",
        "    def _calculate_decisiveness(self, values):\n",
        "        # Decisiveness = Arithmetic mean\n",
        "        result = tf.reduce_sum(values) * self.inv_n\n",
        "        return result.numpy()\n",
        "\n",
        "    def _calculate_accuracy(self, values):\n",
        "        # Accuracy = Geometric mean\n",
        "        result = tf.reduce_prod(values ** self.inv_n)\n",
        "        return result.numpy()\n",
        "\n",
        "    def _calculate_robustness(self, values):\n",
        "        # Robustness = -2/3 Mean\n",
        "        result = tf.reduce_sum(values ** (-2/3))\n",
        "        result = (result * self.inv_n) ** (-3/2)\n",
        "        return result.numpy()\n",
        "\n",
        "    def get_metrics(self):\n",
        "        return self.gmean_metrics\n",
        "\n",
        "    def get_log_prob_values(self):\n",
        "        return self.gmean_log_prob_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHSLR0nPIKzx"
      },
      "source": [
        "class Visualize:\n",
        "\n",
        "    def __init__(self, sample_func, z_sample, sample_labels, gmean_metrics,\n",
        "                 gmean_log_prob_values, display_path='.'\n",
        "                 ):\n",
        "        self.sample_func = sample_func\n",
        "        self.z_sample = z_sample\n",
        "        self.sample_labels = sample_labels\n",
        "        self.gmean_metrics = gmean_metrics\n",
        "        self.gmean_log_prob_values = gmean_log_prob_values\n",
        "        self.display_path = display_path\n",
        "        if len(z_sample) <= 16:\n",
        "            sample_images = sample_func(z_sample)  # predictions\n",
        "        else:\n",
        "            sample_images = sample_func(z_sample)[:16]  # first 16 predictions\n",
        "        self.sample_images = sample_images\n",
        "        self.digit_size = len(sample_images[0])\n",
        "\n",
        "    def display(self, show=True, **kwargs):\n",
        "        self.display_generated_images(show=show, **kwargs)\n",
        "        self.display_latent_space(show=show, **kwargs)\n",
        "        self.display_manifold(show=show, **kwargs)\n",
        "        self.display_histogram(key='recon', show=show, **kwargs)\n",
        "        self.display_histogram(key='kldiv', show=show, **kwargs)\n",
        "        self.display_histogram(key='elbo', show=show, **kwargs)\n",
        "\n",
        "    def display_generated_images(self, image_size=4, show=True, **kwargs):\n",
        "        fig = plt.figure(figsize=(image_size, image_size))\n",
        "        for i in range(self.sample_images.shape[0]):\n",
        "            plt.subplot(4, 4, i + 1)\n",
        "            plt.imshow(self.sample_images[i, :, :, 0], cmap='gray')\n",
        "            plt.axis('off')\n",
        "        # tight_layout minimizes the overlap between 2 sub-plots\n",
        "        plt.axis('Off')\n",
        "        plt.savefig(f\"{self.display_path}/generated_images/\" + \\\n",
        "                    f\"{self._picture_name('images', **kwargs)}\"\n",
        "                    )\n",
        "        if show:\n",
        "            plt.show();\n",
        "\n",
        "    def display_latent_space(self, image_size=4, show=True, **kwargs):\n",
        "        # display a 2D plot of the digit classes in the latent space\n",
        "        # Write T-SNE code here:\n",
        "        # T-SNE ---\n",
        "        ###\n",
        "        colors = ['pink', 'red', 'orange', 'yellow', 'green',\n",
        "                  'blue', 'purple', 'brown', 'gray', 'black'\n",
        "                  ]\n",
        "        plt.figure(figsize=(image_size, image_size))\n",
        "        plt.scatter(self.z_sample[:, 0], self.z_sample[:, 1], c=self.sample_labels,\n",
        "                    cmap=matplotlib.colors.ListedColormap(colors)\n",
        "                    )\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('z[0]')\n",
        "        plt.ylabel('z[1]')\n",
        "        plt.savefig(f\"{self.display_path}/latent_spaces/\" + \\\n",
        "                    f\"{self._picture_name('latent', **kwargs)}\"\n",
        "                    )\n",
        "        if show:\n",
        "            plt.show();\n",
        "\n",
        "    def display_manifold(self, n=20, image_size=10, show=True, **kwargs):\n",
        "        \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
        "        norm = tfp.distributions.Normal(0, 1)\n",
        "        grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "        grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "        image_width = self.digit_size*n\n",
        "        image_height = image_width\n",
        "        image = np.zeros((image_height, image_width))\n",
        "        for i, yi in enumerate(grid_x):\n",
        "            for j, xi in enumerate(grid_y):\n",
        "                z = np.array([[xi, yi]])\n",
        "                x_decoded = self.sample_func(z)\n",
        "                digit = tf.reshape(x_decoded[0], \n",
        "                                   (self.digit_size, self.digit_size)\n",
        "                                   )\n",
        "                image[i*self.digit_size: (i+1)*self.digit_size,\n",
        "                      j*self.digit_size: (j+1)*self.digit_size] = digit.numpy()\n",
        "        plt.figure(figsize=(image_size, image_size))\n",
        "        plt.imshow(image, cmap='Greys_r')\n",
        "        plt.axis('Off')\n",
        "        plt.savefig(f\"{self.display_path}/manifolds/\" + \\\n",
        "                    f\"{self._picture_name('mani', **kwargs)}\"\n",
        "                    )\n",
        "        if show:\n",
        "            plt.show();\n",
        "\n",
        "    def display_histogram(self, key, image_size=(24, 10), show=True, **kwargs):\n",
        "        # Get histogram title and x-axis\n",
        "        if key == 'recon':\n",
        "            # xlabel = 'Probability of reconstructed image equivalent to original one.'\n",
        "            xlabel = 'Reconstruction Probability'\n",
        "            xticks = [1e-240, 1e-210, 1e-180, 1e-150, 1e-120, 1e-90, 1e-60, 1e-30, 1]\n",
        "        elif key == 'kldiv':\n",
        "            xlabel = 'Divergence Probability'\n",
        "            xticks = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "        else:\n",
        "            xlabel = 'ELBO Probability'\n",
        "            xticks = [1e-240, 1e-210, 1e-180, 1e-150, 1e-120, 1e-90, 1e-60, 1e-30, 1]\n",
        "        # Retrieve the generalized means and metric values\n",
        "        decisiveness = self.gmean_metrics[f'{key}_decisiveness']\n",
        "        accuracy = self.gmean_metrics[f'{key}_accuracy']\n",
        "        robustness = self.gmean_metrics[f'{key}_robustness']\n",
        "        log_prob_values = self.gmean_log_prob_values[key]\n",
        "        # The histogram of the data\n",
        "        fig, ax = plt.subplots(figsize=(24, 10))\n",
        "        xtick_axis = [math.log(xtick) for xtick in xticks]\n",
        "        xtick_labels = [str(xtick) for xtick in xticks]\n",
        "        ax.set_xticks(xtick_axis)\n",
        "        ax.set_xticklabels(xtick_labels)\n",
        "        plt.title(f\"{xlabel} Histogram for VAE (Epoch={kwargs['epoch']})\", fontdict = {'fontsize' : 40, 'weight': 'bold'})\n",
        "        plt.xlabel(xlabel, fontdict = {'fontsize' : 40, 'weight': 'bold'})\n",
        "        plt.ylabel(\"Frequency in logscale\", fontdict = {'fontsize' : 40, 'weight': 'bold'})\n",
        "        # Plot in logscale, so convert the metric as logs as well\n",
        "        log_dec, log_acc, log_rob = np.log(decisiveness), np.log(accuracy), np.log(robustness)\n",
        "        dec_txt, acc_txt, rob_txt = f'{decisiveness:0.2e}', f'{accuracy:0.2e}', f'{robustness:0.2e}'\n",
        "        plt.axvline(log_dec, color='g', linestyle='dashed', linewidth=2)\n",
        "        plt.text(log_dec, 10*12, dec_txt, color='g', size='large', weight='bold')\n",
        "        plt.axvline(log_acc, color='b', linestyle='dashed', linewidth=2)\n",
        "        plt.text(log_acc, 10*12, acc_txt, color='b', size='large', weight='bold')\n",
        "        plt.axvline(log_rob, color='r', linestyle='dashed', linewidth=2)\n",
        "        plt.text(log_rob, 10*12, rob_txt, color='r', size='large', weight='bold')\n",
        "        plt.hist(log_prob_values, log=True, bins=100, facecolor='white', edgecolor='black')\n",
        "        plt.savefig(f\"{self.display_path}/histograms/{key}/\" + \\\n",
        "                    f\"{self._picture_name(f'hist_{key}', **kwargs)}\"\n",
        "                    )\n",
        "        if show:\n",
        "            plt.show();\n",
        "\n",
        "    def _picture_name(self, display_type, **kwargs):\n",
        "        name = display_type\n",
        "        for key, value in kwargs.items():\n",
        "            name += f'_{key}{str(value)}'\n",
        "        return f'{name}.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_DtMMuTv91K"
      },
      "source": [
        "class VAE:\n",
        "    \"\"\"Variational Autoencoder wrapper.\"\"\"\n",
        "    def __init__(self, z_dim, n_filter_base=32, learning_rate=0.0005,\n",
        "                 beta=1., p_std=1., seed=0, loss_coupling = 0.0,\n",
        "                 analytic_kl=False, display_path='.'\n",
        "                 ):\n",
        "        self.optimizer = tfk.optimizers.Adam(learning_rate)\n",
        "        self.model = VAEModel(z_dim, n_filter_base, seed)\n",
        "        metrics_col = ['epoch', 'neg_elbo', 'recon_loss', 'kl_div'] + \\\n",
        "                      [f'{x}_{y}' for x in ['elbo', 'recon', 'kl'] \n",
        "                                  for y in ['decisiveness', 'accuracy', 'robustness']\n",
        "                       ]\n",
        "        self.metrics_df = pd.DataFrame(columns=metrics_col)\n",
        "        self.beta = beta\n",
        "        self.p_std = p_std\n",
        "        self.analytic_kl = analytic_kl\n",
        "        self.display_path = display_path\n",
        "        self._set_random_seeds(seed)\n",
        "        self.loss_coupling = loss_coupling\n",
        "\n",
        "    def train(self, train_dataset, test_dataset, test_label, n_epoch=10,\n",
        "              n_epoch_display=10\n",
        "              ):\n",
        "        # Pick a sample of the test set for generating output images\n",
        "        for test_batch, test_batch_label in zip(test_dataset.take(1),\n",
        "                                                test_label.take(1)\n",
        "                                                ):\n",
        "            test_sample = test_batch\n",
        "            test_sample_label = test_batch_label\n",
        "        \n",
        "        \n",
        "\n",
        "        for epoch in range(1, n_epoch + 1):\n",
        "            start_time = time.time()\n",
        "            for train_x in tqdm(train_dataset):\n",
        "                self.train_step(train_x)\n",
        "            end_time = time.time()\n",
        "            # Get Loss Metrics\n",
        "            for test_x in test_dataset:\n",
        "                loss, neg_ll, kl_div, ll_values, kl_values = self.compute_loss(test_x)\n",
        "            display.clear_output(wait=False)\n",
        "            print(f\"Epoch: {epoch}, Test set Loss: {loss}, \" + \\\n",
        "                  f\"Test set Recon: {neg_ll}, Test set KL: {kl_div}, \" + \\\n",
        "                  f\"time elapse for current epoch: {end_time - start_time}\"\n",
        "                  )\n",
        "            \n",
        "            # Generalized Mean\n",
        "            gmean = GeneralizedMean(ll_values, kl_values)\n",
        "            # Visualize / Display\n",
        "            display_list = [1, 2, 3, 5, 15]\n",
        "            if epoch in display_list or epoch % n_epoch_display == 0:\n",
        "                z_sample, _, _ = self.model.encoder(test_sample)\n",
        "                viz = Visualize(self.model.sample,\n",
        "                                z_sample,\n",
        "                                test_sample_label,\n",
        "                                gmean.get_metrics(),\n",
        "                                gmean.get_log_prob_values(),\n",
        "                                self.display_path\n",
        "                                )\n",
        "                viz.display(cd='X',\n",
        "                            cl='X',\n",
        "                            epoch=epoch\n",
        "                            )\n",
        "            metrics_row = [int(epoch), loss.numpy(), neg_ll.numpy(), kl_div.numpy()]\n",
        "            metrics_row = pd.Series(metrics_row, index=self.metrics_df.columns[:4])\n",
        "            metrics_row = metrics_row.append(gmean.get_metrics())\n",
        "            self.metrics_df = self.metrics_df.append(metrics_row, ignore_index=True)\n",
        "\n",
        "    # @tf.function\n",
        "    def train_step(self, x_true):\n",
        "        \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "        This function computes the loss and gradients, and uses the latter to\n",
        "        update the model's parameters.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.compute_loss(x_true, True)\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "    def log_normal_pdf(self, sample, mean, logvar, raxis=1):\n",
        "        log2pi = tf.math.log(2. * np.pi)\n",
        "        return tf.reduce_sum(\n",
        "            -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "            axis=raxis)\n",
        "    \n",
        "    def coupled_kl_divergence_vs_standard_mvn_analytical(self, loc, scale, kappa):\n",
        "        \"\"\"\n",
        "        This function calculates the coupled divergence between the input \n",
        "        distribution and the multivariate Gaussian centered at the origin whose\n",
        "        covariance matrix is the identity matrix.\n",
        "        Parameters\n",
        "        ----------\n",
        "        loc : tf.Tensor\n",
        "        scale : tf.Tensor\n",
        "        kappa : float\n",
        "            The coupling of the divergence function.\n",
        "        Returns\n",
        "        -------\n",
        "        coupted_divergence : tf.Tensor\n",
        "            The coupled divergence between an input distribution and the standard\n",
        "            multivariate Gaussian.\n",
        "        \"\"\"\n",
        "\n",
        "        loc_q = loc\n",
        "        scale_q = diag_part(scale)\n",
        "        dim = loc.shape[-1]\n",
        "\n",
        "        d1 = 1 + dim*kappa + 2*kappa  \n",
        "\n",
        "        coupled_div_t1 = add(\n",
        "            multiply(kappa, nsc_tf.math.function.coupled_logarithm(2*pi, kappa=kappa, dim=dim)), 1\n",
        "            )\n",
        "        coupled_div_t1 = multiply(\n",
        "            coupled_div_t1, \n",
        "            sqrt(divide(d1, (subtract(d1, multiply(2*kappa, square(scale_q))))))\n",
        "            )\n",
        "\n",
        "        coupled_div_t1 *= exp(\n",
        "            divide(multiply(multiply(square(loc_q), d1), kappa), \n",
        "                  multiply((1 + dim*kappa), \n",
        "                            (subtract(d1, 2*kappa*square(scale_q)))))\n",
        "            )\n",
        "        coupled_div_t1 = reduce_prod(coupled_div_t1, axis=1)\n",
        "\n",
        "        coupled_div_t2 = multiply(kappa, \n",
        "                                  nsc_tf.math.function.coupled_logarithm(\n",
        "                                      multiply(2*pi, square(scale_q)), \n",
        "                                      kappa=kappa, \n",
        "                                      dim=dim)\n",
        "                                  )\n",
        "        coupled_div_t2 = add(coupled_div_t2, 1)\n",
        "        coupled_div_t2 *= sqrt(d1 / (1 + dim*kappa))\n",
        "        coupled_div_t2 = reduce_prod(coupled_div_t2, axis=1)\n",
        "\n",
        "        coupled_divergence = subtract(coupled_div_t1, coupled_div_t2) \n",
        "        coupled_divergence = divide(coupled_divergence, 2*kappa)\n",
        "\n",
        "        return coupled_divergence\n",
        "\n",
        "    def compute_loss(self, x_true, train=False):\n",
        "        x_recons_logits, z_sample, mean, logvar = self.model(x_true)\n",
        "\n",
        "\n",
        "        if self.loss_coupling == 0.0:\n",
        "          # Sigmoid Cross Entropy Loss\n",
        "          cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_recons_logits,\n",
        "                                                              labels=x_true\n",
        "                                                              )\n",
        "          # Negative Log-Likelihood\n",
        "          logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])  # log-likelihood\n",
        "          neg_ll = -logpx_z  # negative log-likelihood\n",
        "          # KL-Divergence\n",
        "          if self.analytic_kl == True:\n",
        "              sd = tf.math.log(1 + tf.math.exp(logvar))\n",
        "              kl_div = -0.5 * tf.math.reduce_sum(1 + tf.math.log(tf.math.square(sd)) - \\\n",
        "                                                tf.math.square(mean) - \\\n",
        "                                                tf.math.square(sd),\n",
        "                                                axis=1\n",
        "                                                )\n",
        "          else:\n",
        "              logpz = self.log_normal_pdf(z_sample, 0., self.p_std)\n",
        "              logqz_x = self.log_normal_pdf(z_sample, mean, logvar)\n",
        "              kl_div = logqz_x - logpz\n",
        "          # ELBO\n",
        "          neg_ll_mean = tf.math.reduce_mean(neg_ll)\n",
        "          kl_div_mean = tf.math.reduce_mean(kl_div)\n",
        "          # elbo = -self.beta*kl_div_mean + neg_ll_mean\n",
        "          loss = neg_ll_mean + self.beta*kl_div_mean\n",
        "\n",
        "        else:\n",
        "          ##NSC ELBO\n",
        "\n",
        "          #Conversion from logits to probs\n",
        "          p = x_true\n",
        "          q = tf.math.sigmoid(x_recons_logits)\n",
        "\n",
        "          #Calculation of binary log_loss\n",
        "          cross_ent_2 = p*nsc_tf.math.function.coupled_logarithm(q, kappa=self.loss_coupling) + (1-p)*nsc_tf.math.function.coupled_logarithm(1-q, kappa=self.loss_coupling)\n",
        "\n",
        "          logpx_z= tf.reduce_sum(cross_ent_2, axis=[1, 2, 3])\n",
        "          neg_ll = -logpx_z\n",
        "\n",
        "          kl_div = self.coupled_kl_divergence_vs_standard_mvn_analytical(loc=mean, scale=tf.linalg.diag(tf.exp(logvar/2)), kappa=self.loss_coupling)\n",
        "\n",
        "          neg_ll_mean = tf.math.reduce_mean(neg_ll)\n",
        "          kl_div_mean = tf.math.reduce_mean(kl_div)\n",
        "\n",
        "          loss = neg_ll_mean + self.beta*kl_div_mean\n",
        "\n",
        "\n",
        "        if train:\n",
        "            return loss\n",
        "        return loss, neg_ll_mean, kl_div_mean, \\\n",
        "               tf.cast(logpx_z, tf.float64), tf.cast(kl_div, tf.float64)\n",
        "\n",
        "    def _set_random_seeds(self, seed):\n",
        "        tf.random.set_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPBEVeMUyq6s"
      },
      "source": [
        "#### **4) Models Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y2l3hhBBoSt"
      },
      "source": [
        "datasets['mnist']['train'], datasets['mnist']['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JGeXi6pKqEQ"
      },
      "source": [
        "datasets['mnist_corrupted/motion_blur']['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb25Xw1OB62B"
      },
      "source": [
        "# datasets['cifar10']['train'], datasets['cifar10']['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMKOS-wB2GKh"
      },
      "source": [
        "# SET HYPERPARAMETERS HERE ####################################################\n",
        "\n",
        "# vae init params\n",
        "z_dim = 2  # latent dim, set the dimensionality of the latent space to a plane for visualization later\n",
        "n_filter_base = 32  # number of base filters in the CNN (a lot of filters?)\n",
        "learning_rate = 0.0005  # uses for the internal Adam opt\n",
        "# vae train params\n",
        "n_epoch = 10  # 100 number of epochs\n",
        "n_epoch_display = 5  # 10 number of epochs before displaying plots\n",
        "show_display = True\n",
        "display_sample = False\n",
        "\n",
        "analytic_kl = True\n",
        "beta = 1.\n",
        "p_std = 1.\n",
        "\n",
        "version = 'v4.3'\n",
        "save_path = f'gdrive/My Drive/Colab Notebooks/coupled_vae/vae/output/{version}/'\n",
        "\n",
        "print(f\"Your current randomly generated seed is {random_seed}. DON'T LOSE TRACK OF YOUR SEEDS!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GrjIvKcm7_l"
      },
      "source": [
        "def create_gdrive_output_folders(save_path, seed):\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "    seed_path = f'{save_path}seed{seed}/'\n",
        "    if os.path.isdir(seed_path):\n",
        "        return\n",
        "    os.mkdir(seed_path)\n",
        "\n",
        "    img_folders = ['identity', 'motion_blur', 'rotate', 'translate']\n",
        "    viz_folders = ['generated_images', 'latent_spaces', 'manifolds', \n",
        "                   'histograms', 'metrics'\n",
        "                   ]\n",
        "\n",
        "    for img_folder in img_folders:\n",
        "        img_path = f'{seed_path}{img_folder}/'\n",
        "        os.mkdir(img_path)\n",
        "\n",
        "        for viz_folder in viz_folders:\n",
        "            viz_path = f'{img_path}{viz_folder}/'\n",
        "            os.mkdir(viz_path)\n",
        "\n",
        "            if viz_folder == 'histograms':\n",
        "                os.mkdir(f'{viz_path}elbo/')\n",
        "                os.mkdir(f'{viz_path}recon/')\n",
        "                os.mkdir(f'{viz_path}kldiv/')\n",
        "\n",
        "create_gdrive_output_folders(save_path, random_seed)  # Will not override existing version and seed folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CesgDe_Ip3kJ"
      },
      "source": [
        "vae_list = {}\n",
        "\n",
        "save_path += f'seed{random_seed}/'\n",
        "print(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESLirGkZ_1oW"
      },
      "source": [
        "%%time\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "for test_name in datasets_names[1:]:  # excluding 'mnist', only 'mnist_corrupted/*'\n",
        "    # display_name = 'original' if test_name == 'mnist' else test_name.split('/')[-1]\n",
        "    display_name = test_name.split('/')[-1]\n",
        "    display_path = save_path + display_name\n",
        "    vae_list[display_name] = VAE(z_dim=z_dim,\n",
        "                                 beta=beta,\n",
        "                                 p_std=p_std,\n",
        "                                 seed=random_seed,\n",
        "                                 loss_coupling=0.001,\n",
        "                                 analytic_kl=analytic_kl,\n",
        "                                 display_path=display_path\n",
        "                                 )\n",
        "    vae_list[display_name].train(train_dataset=datasets['mnist']['train'],\n",
        "                                 test_dataset=datasets[test_name]['test'],\n",
        "                                 test_label=datasets[test_name]['test_label'],\n",
        "                                 n_epoch=n_epoch,\n",
        "                                 n_epoch_display=n_epoch_display,\n",
        "                                 )\n",
        "    # Save to metrics tables.csv\n",
        "    vae_list[display_name].metrics_df.to_csv(f\"{display_path}/metrics/table.csv\",\n",
        "                                             index=False\n",
        "                                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNgwexM8UQsw"
      },
      "source": [
        "vae_list.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iy6-7zLHt-r"
      },
      "source": [
        "#### **5) Models Display**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ps4RQMqEX5E"
      },
      "source": [
        "Use vanilla VAE model with prior std = 1 as example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbMNo5D8EXV1"
      },
      "source": [
        "vae = vae_list['identity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M0id04neWCA"
      },
      "source": [
        "# def display_image(epoch_no):\n",
        "#     return PIL.Image.open(f\"{display_path}/generated_images/{_picture_name('images', epoch=epoch_no)}\")\n",
        "#     # return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmrpeyKmHtk-"
      },
      "source": [
        "# plt.imshow(display_image(n_epoch))\n",
        "# plt.axis('off')  # Display images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKoCFE7EH7AM"
      },
      "source": [
        "# anim_file = 'cvae.gif'\n",
        "\n",
        "# with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "#     filenames = glob.glob('image*.png')\n",
        "#     filenames = sorted(filenames)\n",
        "#     for filename in filenames:\n",
        "#         image = imageio.imread(filename)\n",
        "#         writer.append_data(image)\n",
        "#     image = imageio.imread(filename)\n",
        "#     writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-iaj_akH7DY"
      },
      "source": [
        "# import tensorflow_docs.vis.embed as embed\n",
        "# embed.embed_file(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WAUzHTjIC12"
      },
      "source": [
        "def plot_latent_images(model, n, digit_size=28):\n",
        "    \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
        "    norm = tfp.distributions.Normal(0, 1)\n",
        "    grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "    grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
        "    image_width = digit_size*n\n",
        "    image_height = image_width\n",
        "    image = np.zeros((image_height, image_width))\n",
        "\n",
        "    for i, yi in enumerate(grid_x):\n",
        "        for j, xi in enumerate(grid_y):\n",
        "            z = np.array([[xi, yi]])\n",
        "            x_decoded = model.sample(z)\n",
        "            digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
        "            image[i * digit_size: (i + 1) * digit_size,\n",
        "                j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image, cmap='Greys_r')\n",
        "    plt.axis('Off')\n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ-7JvLqIC9W"
      },
      "source": [
        "plot_latent_images(vae.model, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xgJdmmZjydU"
      },
      "source": [
        "Summarize history for loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JbO6zmbH07D"
      },
      "source": [
        "def lighten_color(color, amount=0.5):\n",
        "    \"\"\"\n",
        "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
        "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
        "\n",
        "    Examples:\n",
        "    >> lighten_color('g', 0.3)\n",
        "    >> lighten_color('#F034A3', 0.6)\n",
        "    >> lighten_color((.3,.55,.1), 0.5)\n",
        "    \"\"\"\n",
        "    import matplotlib.colors as mc\n",
        "    import colorsys\n",
        "    try:\n",
        "        c = mc.cnames[color]\n",
        "    except:\n",
        "        c = color\n",
        "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
        "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSHeI2hpEsQf"
      },
      "source": [
        "x = range(1, n_epoch + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWAtSqOUubQF"
      },
      "source": [
        "for key, vae in vae_list.items():\n",
        "    y = vae.metrics_df['neg_elbo']\n",
        "    plt.plot(x, y, label=key)\n",
        "plt.title('VAE Total Loss vs Epoch')\n",
        "plt.ylabel('Total Loss (negELBO)')\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylim(ymin=0)\n",
        "plt.legend(title='MNIST type')\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CTC0_Guu3mV"
      },
      "source": [
        "for key, vae in vae_list.items():\n",
        "    y = vae.metrics_df['recon_loss']\n",
        "    plt.plot(x, y, label=key)\n",
        "plt.title('VAE Reconstruction Loss vs Epoch')\n",
        "plt.ylabel('Reconstruction Loss (NLL)')\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylim(ymin=0)\n",
        "plt.legend(title='beta')\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R03g1dnNu5M0"
      },
      "source": [
        "for key, vae in vae_list.items():\n",
        "    y = vae.metrics_df['kl_div']\n",
        "    plt.plot(x, y, label=key)\n",
        "plt.title('VAE KL-Divergence vs Epoch')\n",
        "plt.ylabel('KL-Divergence')\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylim(ymin=0)\n",
        "plt.legend(title='beta')\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqGxrCeZvkDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}